{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# (8 cores, 16gb per machine) x 5 = 40 cores\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.1.153:7077\") \\\n",
    "        .appName(\"martin_luther_king\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862234\n",
      "1862234\n",
      "Yes they match :)\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def split_line(line):\n",
    "    return line.split('\\n')\n",
    "\n",
    "\n",
    "# A.1.1\n",
    "linesEN = spark_context.textFile(\"hdfs://192.168.1.153:9000/europarl/europarl-v7.sv-en.en\")\n",
    "print(linesEN.count())\n",
    "# A.1.2\n",
    "linesSWE = spark_context.textFile(\"hdfs://192.168.1.153:9000/europarl/europarl-v7.sv-en.sv\")\n",
    "print(linesSWE.count())\n",
    "# A.1.3\n",
    "if(linesSWE.count() == linesEN.count()):\n",
    "    print(\"Yes they match :)\")\n",
    "\n",
    "# A.1.4\n",
    "# English partitions\n",
    "print(linesEN.getNumPartitions())\n",
    "\n",
    "# Swedish partitions\n",
    "print(linesSWE.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['resumption', 'of', 'the', 'session'], ['i', 'declare', 'resumed', 'the', 'session', 'of', 'the', 'european', 'parliament', 'adjourned', 'on', 'friday', '17', 'december', '1999,', 'and', 'i', 'would', 'like', 'once', 'again', 'to', 'wish', 'you', 'a', 'happy', 'new', 'year', 'in', 'the', 'hope', 'that', 'you', 'enjoyed', 'a', 'pleasant', 'festive', 'period.'], ['although,', 'as', 'you', 'will', 'have', 'seen,', 'the', 'dreaded', \"'millennium\", \"bug'\", 'failed', 'to', 'materialise,', 'still', 'the', 'people', 'in', 'a', 'number', 'of', 'countries', 'suffered', 'a', 'series', 'of', 'natural', 'disasters', 'that', 'truly', 'were', 'dreadful.'], ['you', 'have', 'requested', 'a', 'debate', 'on', 'this', 'subject', 'in', 'the', 'course', 'of', 'the', 'next', 'few', 'days,', 'during', 'this', 'part-session.'], ['in', 'the', 'meantime,', 'i', 'should', 'like', 'to', 'observe', 'a', \"minute'\", 's', 'silence,', 'as', 'a', 'number', 'of', 'members', 'have', 'requested,', 'on', 'behalf', 'of', 'all', 'the', 'victims', 'concerned,', 'particularly', 'those', 'of', 'the', 'terrible', 'storms,', 'in', 'the', 'various', 'countries', 'of', 'the', 'european', 'union.'], ['please', 'rise,', 'then,', 'for', 'this', \"minute'\", 's', 'silence.'], ['(the', 'house', 'rose', 'and', 'observed', 'a', \"minute'\", 's', 'silence)'], ['madam', 'president,', 'on', 'a', 'point', 'of', 'order.'], ['you', 'will', 'be', 'aware', 'from', 'the', 'press', 'and', 'television', 'that', 'there', 'have', 'been', 'a', 'number', 'of', 'bomb', 'explosions', 'and', 'killings', 'in', 'sri', 'lanka.'], ['one', 'of', 'the', 'people', 'assassinated', 'very', 'recently', 'in', 'sri', 'lanka', 'was', 'mr', 'kumar', 'ponnambalam,', 'who', 'had', 'visited', 'the', 'european', 'parliament', 'just', 'a', 'few', 'months', 'ago.']]\n",
      "[['återupptagande', 'av', 'sessionen'], ['jag', 'förklarar', 'europaparlamentets', 'session', 'återupptagen', 'efter', 'avbrottet', 'den', '17', 'december.', 'jag', 'vill', 'på', 'nytt', 'önska', 'er', 'ett', 'gott', 'nytt', 'år', 'och', 'jag', 'hoppas', 'att', 'ni', 'haft', 'en', 'trevlig', 'semester.'], ['som', 'ni', 'kunnat', 'konstatera', 'ägde', '\"den', 'stora', 'år', '2000-buggen\"', 'aldrig', 'rum.', 'däremot', 'har', 'invånarna', 'i', 'ett', 'antal', 'av', 'våra', 'medlemsländer', 'drabbats', 'av', 'naturkatastrofer', 'som', 'verkligen', 'varit', 'förskräckliga.'], ['ni', 'har', 'begärt', 'en', 'debatt', 'i', 'ämnet', 'under', 'sammanträdesperiodens', 'kommande', 'dagar.'], ['till', 'dess', 'vill', 'jag', 'att', 'vi,', 'som', 'ett', 'antal', 'kolleger', 'begärt,', 'håller', 'en', 'tyst', 'minut', 'för', 'offren', 'för', 'bl.a.', 'stormarna', 'i', 'de', 'länder', 'i', 'europeiska', 'unionen', 'som', 'drabbats.'], ['jag', 'ber', 'er', 'resa', 'er', 'för', 'en', 'tyst', 'minut.'], ['(parlamentet', 'höll', 'en', 'tyst', 'minut.)'], ['fru', 'talman!', 'det', 'gäller', 'en', 'ordningsfråga.'], ['ni', 'känner', 'till', 'från', 'media', 'att', 'det', 'skett', 'en', 'rad', 'bombexplosioner', 'och', 'mord', 'i', 'sri', 'lanka.'], ['en', 'av', 'de', 'personer', 'som', 'mycket', 'nyligen', 'mördades', 'i', 'sri', 'lanka', 'var', 'kumar', 'ponnambalam,', 'som', 'besökte', 'europaparlamentet', 'för', 'bara', 'några', 'månader', 'sedan.']]\n",
      "Yes they match :)\n"
     ]
    }
   ],
   "source": [
    "# A.2.1\n",
    "# lower case function \n",
    "def lower_case(line):\n",
    "    lower = line.map(lambda x: x.lower())\n",
    "    return lower\n",
    "\n",
    "# lower case english\n",
    "lower_english = lower_case(linesEN)\n",
    "\n",
    "# lower case swedish\n",
    "lower_swedish = lower_case(linesSWE)\n",
    "\n",
    "# split space function \n",
    "def split_space(line):\n",
    "    splitz = line.split(' ')\n",
    "    return splitz\n",
    "\n",
    "# split words english\n",
    "split_english = lower_english.map(split_space)\n",
    "\n",
    "# split words swedish\n",
    "split_swedish = lower_swedish.map(split_space)\n",
    "\n",
    "# A.2.2\n",
    "print(split_english.take(10))\n",
    "print(split_swedish.take(10))\n",
    "\n",
    "# A.2.3\n",
    "if(split_english.count() == split_swedish.count()):\n",
    "    print(\"Yes they match :)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3498375), ('of', 1659758), ('to', 1539760), ('and', 1288401), ('in', 1085993), ('that', 797516), ('a', 773522), ('is', 758050), ('for', 534242), ('we', 522849)]\n",
      "[('att', 1706293), ('och', 1344830), ('i', 1050774), ('det', 924866), ('som', 913276), ('för', 908680), ('av', 738068), ('är', 694381), ('en', 620310), ('vi', 539797)]\n",
      "\n",
      "Considering the number of lines, yes the word counts do seem reasonable\n"
     ]
    }
   ],
   "source": [
    "# A.3.1\n",
    "def word_count(line):\n",
    "    county = line.map(lambda w: (w,1)).reduceByKey(lambda a, b : a+b).takeOrdered(10, lambda x: -x[1])\n",
    "    return county\n",
    "\n",
    "\n",
    "# preprocessed english text -> using function from above  \n",
    "english_corpus = lower_english.flatMap(split_space)    \n",
    "\n",
    "\n",
    "# preprocessed swedish text -> using function from above  \n",
    "swedish_corpus = lower_swedish.flatMap(split_space) \n",
    "\n",
    "\n",
    "# 10 most frequent words English\n",
    "most_freq_english = word_count(english_corpus)\n",
    "print(most_freq_english)\n",
    "\n",
    "# 10 most frequent words Swedish\n",
    "most_freq_swedish = word_count(swedish_corpus)\n",
    "print(most_freq_swedish)\n",
    "\n",
    "\n",
    "# A.3.2\n",
    "print(\"\")\n",
    "print(\"Considering the number of lines, yes the word counts do seem reasonable\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('is', 'är'), 10040), (('we', 'vi'), 5530), (('i', 'jag'), 5020), (('this', 'detta'), 3252), (('closed.', 'avslutad.'), 2964), (('and', 'och'), 2917), (('a', 'en'), 2888), (('it', 'det'), 2866), (('that', 'det'), 2806), (('not', 'inte'), 2650)]\n"
     ]
    }
   ],
   "source": [
    "# A.4.1\n",
    "\n",
    "# 1: key the lines by their line number using RDDs from A.2\n",
    "en_1 = split_english.zipWithIndex()\n",
    "sv_1 = split_swedish.zipWithIndex()\n",
    "\n",
    "# 2: swap the key and value - line number is the key\n",
    "en_2 = en_1.map(lambda x: (x[1], x[0]))\n",
    "sv_2 = sv_1.map(lambda x: (x[1], x[0]))\n",
    "\n",
    "# 3: join the two RDDs together\n",
    "en_sw_3 = en_2.join(sv_2)\n",
    "\n",
    "# 4: filter to exclude line pairs that have an empty/ missing sentence\n",
    "def if_empty(x):\n",
    "    if((len(x[1][1]) > 0) and (len(x[1][0]) > 0)):\n",
    "        return x\n",
    "\n",
    "en_sw_4 = en_sw_3.filter(if_empty)\n",
    "\n",
    "# 5: filter to leave only pairs of sentence with small number of words\n",
    "def num_words(x):\n",
    "    if((len(x[1][1]) < 10) and (len(x[1][0]) < 10)):\n",
    "        return x\n",
    "    \n",
    "en_sw_5 = en_sw_4.filter(num_words)\n",
    "\n",
    "# 6: filter to leave only pairs of sentences with the same number of words in each sentence\n",
    "def same_num(x):\n",
    "    if((len(x[1][1]) == len(x[1][0]))):\n",
    "        return x\n",
    "    \n",
    "en_sw_6 = en_sw_5.filter(same_num)\n",
    "\n",
    "\n",
    "\n",
    "# 7: for each sentence pair, map so that you pair each in order word in the two sentences --> use zip \n",
    "def zipped(x):\n",
    "    x = zip(x[1][0],x[1][1])\n",
    "    x = list(x)\n",
    "    return x\n",
    "\n",
    "en_sw_7 = en_sw_6.flatMap(zipped)\n",
    "\n",
    "# 8: use reduce to count the number of occurences of the word-translation-pairs\n",
    "def tuple_count(line):\n",
    "    county = line.map(lambda w: (w,1)).reduceByKey(lambda a, b : a+b)\n",
    "    return county\n",
    "\n",
    "en_sw_8 = tuple_count(en_sw_7)\n",
    "\n",
    "# 9 : print some of the most frequently occuring pair of words\n",
    "en_sw_9 = en_sw_8.takeOrdered(10, lambda x : -x[1])\n",
    "print(en_sw_9)\n",
    "\n",
    "# yes, the majority of the translations seem reasonable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "# spark_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
